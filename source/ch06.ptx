<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="ch-inference-for-props" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Inference for Categorical Data</title>
  
  <introduction>
    <p>
      In this chapter, we apply the methods and ideas from Chapter 5 in several contexts for
      categorical data. We'll start by revisiting what we learned for a single proportion, where
      the normal distribution can be used to model the uncertainty in the sample proportion. Next,
      we apply these same ideas to analyze the difference of two proportions using the normal model.
      Later in the chapter, we apply inference techniques to contingency tables; while we will use
      a different distribution in this context, the core ideas of hypothesis testing remain the same.
    </p>
  </introduction>
  
  <!-- Section 6.1: Inference for a single proportion -->
  <section xml:id="singleProportion">
    <title>Inference for a single proportion</title>
    
    <introduction>
      <p>
        We encountered inference methods for a single proportion in Chapter<nbsp/>5, exploring point estimates, confidence intervals, and hypothesis tests. In this section, we'll do a review of these topics and also how to choose an appropriate sample size when collecting data for single proportion contexts.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-sample-prop-normal">
      <title>Identifying when the sample proportion is nearly normal</title>
      
      <p>
        A sample proportion <m>\hat{p}</m> can be modeled using a normal distribution when the sample observations are independent and the sample size is sufficiently large.
      </p>
      
      <assemblage xml:id="assem-sampling-dist-p-hat">
        <title>Sampling distribution of <m>\hat{p}</m></title>
        <p>
          The sampling distribution for <m>\hat{p}</m> based on a sample of size <m>n</m> from a population with a true proportion <m>p</m> is nearly normal when:
        </p>
        <ol>
          <li>The sample's observations are independent, e.g. are from a simple random sample.</li>
          <li>We expected to see at least 10 successes and 10 failures in the sample, i.e. <m>np \geq 10</m> and <m>n(1-p) \geq 10</m>. This is called the <term>success-failure condition</term>.</li>
        </ol>
        <p>
          When these conditions are met, then the sampling distribution of <m>\hat{p}</m> is nearly normal with mean <m>p</m> and standard error <m>SE = \sqrt{\frac{p(1-p)}{n}}</m>.
        </p>
      </assemblage>
      
      <p>
        Typically we don't know the true proportion <m>p</m>, so we substitute some value to check conditions and estimate the standard error. For confidence intervals, the sample proportion <m>\hat{p}</m> is used to check the success-failure condition and compute the standard error. For hypothesis tests, typically the null value<mdash/>that is, the proportion claimed in the null hypothesis<mdash/>is used in place of <m>p</m>.
      </p>
    </subsection>
    
    <subsection xml:id="confIntForPropSection">
      <title>Confidence intervals for a proportion</title>
      
      <p>
        A confidence interval provides a range of plausible values for the parameter <m>p</m>, and when <m>\hat{p}</m> can be modeled using a normal distribution, the confidence interval for <m>p</m> takes the form
      </p>
      <me>
        \hat{p} \pm z^{\star} \times SE
      </me>
      
      <example xml:id="ex-payday-normal-check">
        <statement>
          <p>
            A simple random sample of 826 payday loan borrowers was surveyed to better understand their interests around regulation and costs. 70% of the responses supported new regulations on payday lenders. Is it reasonable to model <m>\hat{p} = 0.70</m> using a normal distribution?
          </p>
        </statement>
        <solution>
          <p>
            The data are a random sample, so the observations are independent and representative of the population of interest.
          </p>
          <p>
            We also must check the success-failure condition, which we do using <m>\hat{p}</m> in place of <m>p</m> when computing a confidence interval:
          </p>
          <md>
            <mrow>\text{Support: } n p \amp \approx 826 \times 0.70 = 578</mrow>
            <mrow>\text{Not: } n (1 - p) \amp \approx 826 \times (1 - 0.70) = 248</mrow>
          </md>
          <p>
            Since both values are at least 10, we can use the normal distribution to model <m>\hat{p}</m>.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="seOfPropOfPDBorrowersSupportReg">
        <statement>
          <p>
            Estimate the standard error of <m>\hat{p} = 0.70</m>. Because <m>p</m> is unknown and the standard error is for a confidence interval, use <m>\hat{p}</m> in place of <m>p</m> in the formula.
          </p>
        </statement>
        <solution>
          <p>
            <m>SE = \sqrt{\frac{p(1-p)}{n}} \approx \sqrt{\frac{0.70 (1 - 0.70)}{826}} = 0.016</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-payday-ci">
        <statement>
          <p>
            Construct a 95% confidence interval for <m>p</m>, the proportion of payday borrowers who support increased regulation for payday lenders.
          </p>
        </statement>
        <solution>
          <p>
            Using the point estimate 0.70, <m>z^{\star} = 1.96</m> for a 95% confidence interval, and the standard error <m>SE = 0.016</m> from Guided Practice<nbsp/><xref ref="seOfPropOfPDBorrowersSupportReg"/>, the confidence interval is
          </p>
          <md>
            <mrow>\text{point estimate} \pm z^{\star} \times SE \amp \to 0.70 \pm 1.96 \times 0.016</mrow>
            <mrow>\amp \to (0.669, 0.731)</mrow>
          </md>
          <p>
            We are 95% confident that the true proportion of payday borrowers who supported regulation at the time of the poll was between 0.669 and 0.731.
          </p>
        </solution>
      </example>
      
      <p>
        For additional one-proportion confidence interval examples, see Section<nbsp/>5.2.
      </p>
    </subsection>
    
    <subsection xml:id="htForPropSection">
      <title>Hypothesis testing for a proportion</title>
      
      <p>
        One possible regulation for payday lenders is that they would be required to do a credit check and evaluate debt payments against the borrower's finances. We would like to know: would borrowers support this form of regulation?
      </p>
      
      <exercise xml:id="paydayCC_hypotheses_gp">
        <statement>
          <p>
            Set up hypotheses to evaluate whether borrowers have a majority support or majority opposition for this type of regulation.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: <m>p = 0.50</m>. <m>H_A</m>: <m>p \neq 0.50</m>.
          </p>
        </solution>
      </exercise>
      
      <p>
        To apply the normal distribution framework in the context of a hypothesis test for a proportion, the independence and success-failure conditions must be satisfied. In a hypothesis test, the success-failure condition is checked using the null proportion: we verify <m>np_0</m> and <m>n(1-p_0)</m> are at least 10, where <m>p_0</m> is the null value.
      </p>
      
      <exercise xml:id="paydayCC_conditions_gp">
        <statement>
          <p>
            Do payday loan borrowers support a regulation that would require lenders to pull their credit report and evaluate their debt payments? From a random sample of 826 borrowers, 51% said they would support such a regulation. Is it reasonable to model <m>\hat{p} = 0.51</m> using a normal distribution for a hypothesis test here?
          </p>
        </statement>
        <solution>
          <p>
            Independence holds since the poll is based on a random sample. The success-failure condition also holds, which is checked using the null value (<m>p_0 = 0.5</m>) from <m>H_0</m>: <m>np_0 = 826 \times 0.5 = 413</m>, <m>n(1 - p_0) = 826 \times 0.5 = 413</m>.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-payday-ht">
        <statement>
          <p>
            Using the hypotheses and data from Guided Practice<nbsp/><xref ref="paydayCC_hypotheses_gp"/> and<nbsp/><xref ref="paydayCC_conditions_gp"/>, evaluate whether the poll provides convincing evidence that a majority of payday loan borrowers support a new regulation that would require lenders to pull credit reports and evaluate debt payments.
          </p>
        </statement>
        <solution>
          <p>
            With hypotheses already set up and conditions checked, we can move onto calculations. The standard error in the context of a one-proportion hypothesis test is computed using the null value, <m>p_0</m>:
          </p>
          <me>
            SE = \sqrt{\frac{p_0 (1 - p_0)}{n}} = \sqrt{\frac{0.5 (1 - 0.5)}{826}} = 0.017
          </me>
          <p>
            A picture of the normal model is shown below with the p-value represented by the shaded region.
          </p>
          <figure xml:id="fig-paydayCC-norm-pvalue">
            <caption>A normal distribution is shown with a center of 0.5 and a standard deviation of 0.017. Two tails are shaded: The region above 0.51 and a region in the corresponding lower tail. Visually, it looks like a little over half of the area under the normal curve is shaded.</caption>
            <image source="ch_inference_for_props/paydayCC_norm_pvalue.pdf" width="50%"/>
          </figure>
          <p>
            Based on the normal model, the test statistic can be computed as the Z-score of the point estimate:
          </p>
          <me>
            Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.51 - 0.50}{0.017} = 0.59
          </me>
          <p>
            The single tail area is 0.2776, and the p-value, represented by both tail areas together, is 0.5552. Because the p-value is larger than 0.05, we do not reject <m>H_0</m>. The poll does not provide convincing evidence that a majority of payday loan borrowers support or oppose regulations around credit checks and evaluation of debt payments.
          </p>
        </solution>
      </example>
      
      <p>
        For additional one-proportion hypothesis test examples, see Section<nbsp/>5.3.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-conditions-not-met">
      <title>When one or more conditions aren't met</title>
      
      <p>
        We've spent a lot of time discussing conditions for when <m>\hat{p}</m> can be reasonably modeled by a normal distribution. What happens when the success-failure condition fails? What about when the independence condition fails? In either case, the general ideas of confidence intervals and hypothesis tests remain the same, but the strategy or technique used to generate the interval or p-value change.
      </p>
      <p>
        When the success-failure condition isn't met for a hypothesis test, we can simulate the null distribution of <m>\hat{p}</m> using the null value, <m>p_0</m>. The simulation concept is similar to the ideas used in the malaria case study presented in Section<nbsp/>5.1, and an online section outlines this strategy: <url href="http://www.openintro.org/r?go=stat_sim_prop_ht">www.openintro.org/r?go=stat_sim_prop_ht</url>
      </p>
      <p>
        For a confidence interval when the success-failure condition isn't met, we can use what's called the <term>Clopper-Pearson interval</term>. The details are beyond the scope of this book. However, there are many internet resources covering this topic.
      </p>
      <p>
        The independence condition is a more nuanced requirement. When it isn't met, it is important to understand how and why it isn't met. For example, if we took a cluster sample (see Section<nbsp/>1.3), suitable statistical methods are available but would be beyond the scope of even most second or third courses in statistics. On the other hand, we'd be stretched to find any method that we could confidently apply to correct the inherent biases of data from a convenience sample.
      </p>
      <p>
        While this book is scoped to well-constrained statistical problems, do remember that this is just the first book in what is a large library of statistical methods that are suitable for a very wide range of data and contexts.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-choosing-sample-size">
      <title>Choosing a sample size when estimating a proportion</title>
      
      <p>
        When collecting data, we choose a sample size suitable for the purpose of the study. Often times this means choosing a sample size large enough that the <term>margin of error</term><mdash/>which is the part we add and subtract from the point estimate in a confidence interval<mdash/>is sufficiently small that the sample is useful. For example, our task might be to find a sample size <m>n</m> so that the sample proportion is within <m>\pm 0.04</m> of the actual proportion in a 95% confidence interval.
      </p>
      
      <example xml:id="ex-football-stadium-sample-size">
        <statement>
          <p>
            A university newspaper is conducting a survey to determine what fraction of students support a $200 per year increase in fees to pay for a new football stadium. How big of a sample is required to ensure the margin of error is smaller than 0.04 using a 95% confidence level?
          </p>
        </statement>
        <solution>
          <p>
            The margin of error for a sample proportion is
          </p>
          <me>
            z^{\star} \sqrt{\frac{p (1 - p)}{n}}
          </me>
          <p>
            Our goal is to find the smallest sample size <m>n</m> so that this margin of error is smaller than 0.04. For a 95% confidence level, the value <m>z^{\star}</m> corresponds to 1.96:
          </p>
          <me>
            1.96\times \sqrt{\frac{p(1-p)}{n}} \ \lt \ 0.04
          </me>
          <p>
            There are two unknowns in the equation: <m>p</m> and <m>n</m>. If we have an estimate of <m>p</m>, perhaps from a prior survey, we could enter in that value and solve for <m>n</m>. If we have no such estimate, we must use some other value for <m>p</m>. It turns out that the margin of error is largest when <m>p</m> is 0.5, so we typically use this <em>worst case value</em> if no estimate of the proportion is available:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{0.5(1-0.5)}{n}} \amp \ \lt \ 0.04</mrow>
            <mrow>1.96^2\times \frac{0.5(1-0.5)}{n} \amp \ \lt \ 0.04^2</mrow>
            <mrow>1.96^2\times \frac{0.5(1-0.5)}{0.04^2} \amp \ \lt \ n</mrow>
            <mrow>600.25 \amp \ \lt \ n</mrow>
          </md>
          <p>
            We would need over 600.25 participants, which means we need 601 participants or more, to ensure the sample proportion is within 0.04 of the true proportion with 95% confidence.
          </p>
        </solution>
      </example>
      
      <p>
        When an estimate of the proportion is available, we use it in place of the worst case proportion value, 0.5.
      </p>
      
      <exercise xml:id="tire_failure_rate_3_samp_size_calc">
        <statement>
          <p>
            A manager is about to oversee the mass production of a new tire model in her factory, and she would like to estimate what proportion of these tires will be rejected through quality control. The quality control team has monitored the last three tire models produced by the factory, failing 1.7% of tires in the first model, 6.2% of the second model, and 1.3% of the third model. The manager would like to examine enough tires to estimate the failure rate of the new tire model to within about 1% with a 90% confidence level. There are three different failure rates to choose from. Perform the sample size computation for each separately, and identify three sample sizes to consider.
          </p>
        </statement>
        <solution>
          <p>
            For a 90% confidence interval, <m>z^{\star} = 1.6449</m>, and since an estimate of the proportion 0.017 is available, we'll use it in the margin of error formula:
          </p>
          <md>
            <mrow>1.6449\times \sqrt{\frac{0.017(1-0.017)}{n}} \amp \ \lt \ 0.01</mrow>
            <mrow>\frac{0.017(1-0.017)}{n} \amp \ \lt \ \left(\frac{0.01}{1.6449}\right)^2</mrow>
            <mrow>452.15 \amp \ \lt \ n</mrow>
          </md>
          <p>
            For sample size calculations, we always round up, so the first tire model suggests 453 tires would be sufficient.
          </p>
          <p>
            A similar computation can be accomplished using 0.062 and 0.013 for <m>p</m>, and you should verify that using these proportions results in minimum sample sizes of 1574 and 348 tires, respectively.
          </p>
        </solution>
      </exercise>
      
      <example xml:id="ex-tire-failure-choice">
        <statement>
          <p>
            The sample sizes vary widely in Guided Practice<nbsp/><xref ref="tire_failure_rate_3_samp_size_calc"/>. Which of the three would you suggest using? What would influence your choice?
          </p>
        </statement>
        <solution>
          <p>
            We could examine which of the old models is most like the new model, then choose the corresponding sample size. Or if two of the previous estimates are based on small samples while the other is based on a larger sample, we might consider the value corresponding to the larger sample. There are also other reasonable approaches.
          </p>
          <p>
            Also observe that the success-failure condition would need to be checked in the final sample. For instance, if we sampled <m>n = 1584</m> tires and found a failure rate of 0.5%, the normal approximation would not be reasonable, and we would require more advanced statistical methods for creating the confidence interval.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-payday-monthly-poll">
        <statement>
          <p>
            Suppose we want to continually track the support of payday borrowers for regulation on lenders, where we would conduct a new poll every month. Running such frequent polls is expensive, so we decide a wider margin of error of 5% for each individual survey would be acceptable. Based on the original sample of borrowers where 70% supported some form of regulation, how big should our monthly sample be for a margin of error of 0.05 with 95% confidence?
          </p>
        </statement>
        <solution>
          <p>
            We complete the same computations as before, except now we use 0.70 instead of 0.5 for <m>p</m>:
          </p>
          <md>
            <mrow>1.96\times \sqrt{\frac{p(1-p)}{n}} \amp \approx 1.96\times \sqrt{\frac{0.70(1-0.70)}{n}} \leq 0.05</mrow>
            <mrow>n \amp \geq 322.7</mrow>
          </md>
          <p>
            A sample size of 323 or more would be reasonable. (Reminder: always round up for sample size calculations!) Given that we plan to track this poll over time, we also may want to periodically repeat these calculations to ensure that we're being thoughtful in our sample size recommendations in case the baseline rate fluctuates.
          </p>
        </solution>
      </exercise>
    </subsection>
    
  </section>
  
  <!-- Section 7.2: Difference of two proportions -->
  <section xml:id="differenceOfTwoProportions">
    <title>Difference of two proportions</title>
    
    <introduction>
      <p>
        We would like to extend the methods from Section<nbsp/><xref ref="singleProportion"/> to apply confidence intervals and hypothesis tests to differences in population proportions: <m>p_1 - p_2</m>. In our investigations, we'll identify a reasonable point estimate of <m>p_1 - p_2</m> based on the sample, and you may have already guessed its form: <m>\hat{p}_1 - \hat{p}_2</m>. Next, we'll apply the same processes we used in the single-proportion context: we verify that the point estimate can be modeled using a normal distribution, we compute the estimate's standard error, and we apply our inferential framework.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-sampling-dist-diff-two-props">
      <title>Sampling distribution of the difference of two proportions</title>
      
      <p>
        Like with <m>\hat{p}</m>, the difference of two sample proportions <m>\hat{p}_1 - \hat{p}_2</m> can be modeled using a normal distribution when certain conditions are met. First, we require a broader independence condition, and secondly, the success-failure condition must be met by both groups.
      </p>
      
      <assemblage xml:id="assem-sampling-dist-p1-p2">
        <title>Conditions for the sampling distribution of <m>\hat{p}_1 - \hat{p}_2</m> to be normal</title>
        <p>
          The difference <m>\hat{p}_1 - \hat{p}_2</m> can be modeled using a normal distribution when
        </p>
        <ul>
          <li>
            <em>Independence, extended.</em> The data are independent within and between the two groups. Generally this is satisfied if the data come from two independent random samples or if the data come from a randomized experiment.
          </li>
          <li>
            <em>Success-failure condition.</em> The success-failure condition holds for both groups, where we check successes and failures in each group separately.
          </li>
        </ul>
        <p>
          When these conditions are satisfied, the standard error of <m>\hat{p}_1 - \hat{p}_2</m> is
        </p>
        <me>
          SE = \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
        </me>
        <p>
          where <m>p_1</m> and <m>p_2</m> represent the population proportions, and <m>n_1</m> and <m>n_2</m> represent the sample sizes.
        </p>
      </assemblage>
    </subsection>
    
    <subsection xml:id="confIntForPropDiffSection">
      <title>Confidence intervals for <m>p_1 - p_2</m></title>
      
      <p>
        We can apply the generic confidence interval formula for a difference of two proportions, where we use <m>\hat{p}_1 - \hat{p}_2</m> as the point estimate and substitute the <m>SE</m> formula:
      </p>
      <md>
        <mrow>\text{point estimate} \pm z^{\star} \times SE \amp \to \hat{p}_1 - \hat{p}_2 \pm z^{\star} \times \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}</mrow>
      </md>
      <p>
        We can also follow the same Prepare, Check, Calculate, Conclude steps for computing a confidence interval or completing a hypothesis test. The details change a little, but the general approach remain the same. Think about these steps when you apply statistical methods.
      </p>
      
      <example xml:id="ex-cpr-check-conditions">
        <statement>
          <p>
            We consider an experiment for patients who underwent cardiopulmonary resuscitation (CPR) for a heart attack and were subsequently admitted to a hospital. These patients were randomly divided into a treatment group where they received a blood thinner or the control group where they did not receive a blood thinner. The outcome variable of interest was whether the patients survived for at least 24 hours. The results are shown in <xref ref="resultsForCPRStudyInSmallSampleSection"/>. Check whether we can model the difference in sample proportions using the normal distribution.
          </p>
        </statement>
        <solution>
          <p>
            We first check for independence: since this is a randomized experiment, this condition is satisfied.
          </p>
          <p>
            Next, we check the success-failure condition for each group. We have at least 10 successes and 10 failures in each experiment arm (11, 14, 39, 26), so this condition is also satisfied.
          </p>
          <p>
            With both conditions satisfied, the difference in sample proportions can be reasonably modeled using a normal distribution for these data.
          </p>
        </solution>
      </example>
      
      <table xml:id="resultsForCPRStudyInSmallSampleSection">
        <title>Results for the CPR study. Patients in the treatment group were given a blood thinner, and patients in the control group were not.</title>
        <tabular>
          <row bottom="minor">
            <cell></cell>
            <cell>Survived</cell>
            <cell>Died</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Control</cell>
            <cell>11</cell>
            <cell>39</cell>
            <cell>50</cell>
          </row>
          <row>
            <cell>Treatment</cell>
            <cell>14</cell>
            <cell>26</cell>
            <cell>40</cell>
          </row>
          <row bottom="minor">
            <cell>Total</cell>
            <cell>25</cell>
            <cell>65</cell>
            <cell>90</cell>
          </row>
        </tabular>
      </table>
      
      <example xml:id="ex-cpr-ci">
        <statement>
          <p>
            Create and interpret a 90% confidence interval of the difference for the survival rates in the CPR study.
          </p>
        </statement>
        <solution>
          <p>
            We'll use <m>p_t</m> for the survival rate in the treatment group and <m>p_c</m> for the control group:
          </p>
          <md>
            <mrow>\hat{p}_{t} - \hat{p}_{c} = \frac{14}{40} - \frac{11}{50} = 0.35 - 0.22 = 0.13</mrow>
          </md>
          <p>
            We use the standard error formula provided on page<nbsp/><xref ref="assem-sampling-dist-p1-p2"/>. As with the one-sample proportion case, we use the sample estimates of each proportion in the formula in the confidence interval context:
          </p>
          <md>
            <mrow>SE \approx \sqrt{\frac{0.35 (1 - 0.35)}{40} + \frac{0.22 (1 - 0.22)}{50}} = 0.095</mrow>
          </md>
          <p>
            For a 90% confidence interval, we use <m>z^{\star} = 1.6449</m>:
          </p>
          <md>
            <mrow>\text{point estimate} \pm z^{\star} \times SE \amp \to 0.13 \pm 1.6449 \times  0.095</mrow>
            <mrow>\amp \to (-0.026, 0.286)</mrow>
          </md>
          <p>
            We are 90% confident that blood thinners have a difference of -2.6% to +28.6% percentage point impact on survival rate for patients who are like those in the study. Because 0% is contained in the interval, we do not have enough information to say whether blood thinners help or harm heart attack patients who have been admitted after they have undergone CPR.
          </p>
        </solution>
      </example>
      
      <exercise xml:id="ex-fish-oil-ci">
        <statement>
          <p>
            A 5-year experiment was conducted to evaluate the effectiveness of fish oils on reducing cardiovascular events, where each subject was randomized into one of two treatment groups. We'll consider heart attack outcomes in these patients:
          </p>
          <table>
            <tabular>
              <row bottom="minor">
                <cell></cell>
                <cell>heart attack</cell>
                <cell>no event</cell>
                <cell>Total</cell>
              </row>
              <row>
                <cell>fish oil</cell>
                <cell>145</cell>
                <cell>12788</cell>
                <cell>12933</cell>
              </row>
              <row>
                <cell>placebo</cell>
                <cell>200</cell>
                <cell>12738</cell>
                <cell>12938</cell>
              </row>
            </tabular>
          </table>
          <p>
            Create a 95% confidence interval for the effect of fish oils on heart attacks for patients who are well-represented by those in the study. Also interpret the interval in the context of the study.
          </p>
        </statement>
        <solution>
          <p>
            Because the patients were randomized, the subjects are independent, both within and between the two groups. The success-failure condition is also met for both groups as all counts are at least 10. This satisfies the conditions necessary to model the difference in proportions using a normal distribution.
          </p>
          <p>
            Compute the sample proportions (<m>\hat{p}_{\text{fish oil}} = 0.0112</m>, <m>\hat{p}_{\text{placebo}} = 0.0155</m>), point estimate of the difference (<m>0.0112 - 0.0155 = -0.0043</m>), and standard error (<m>SE = \sqrt{\frac{0.0112 \times 0.9888}{12933} + \frac{0.0155 \times 0.9845}{12938}} = 0.00145</m>). Next, plug the values into the general formula for a confidence interval, where we'll use a 95% confidence level with <m>z^{\star} = 1.96</m>:
          </p>
          <md>
            <mrow>-0.0043 \pm 1.96 \times 0.00145 \to (-0.0071, -0.0015)</mrow>
          </md>
          <p>
            We are 95% confident that fish oils decreases heart attacks by 0.15 to 0.71 percentage points (off of a baseline of about 1.55%) over a 5-year period for subjects who are similar to those in the study. Because the interval is entirely below 0, the data provide strong evidence that fish oil supplements reduce heart attacks in patients like those in the study.
          </p>
        </solution>
      </exercise>
    </subsection>
    
    <subsection xml:id="htForPropDiffSection">
      <title>Hypothesis tests for the difference of two proportions</title>
      
      <p>
        A mammogram is an X-ray procedure used to check for breast cancer. Whether mammograms should be used is part of a controversial discussion, and it's the topic of our next example where we learn about 2-proportion hypothesis tests when <m>H_0</m> is <m>p_1 - p_2 = 0</m> (or equivalently, <m>p_1 = p_2</m>).
      </p>
      
      <p>
        A 30-year study was conducted with nearly 90,000 female participants. During a 5-year screening period, each woman was randomized to one of two groups: in the first group, women received regular mammograms to screen for breast cancer, and in the second group, women received regular non-mammogram breast cancer exams. No intervention was made during the following 25 years of the study, and we'll consider death resulting from breast cancer over the full 30-year period. Results from the study are summarized in <xref ref="mammogramStudySummaryTable"/>.
      </p>
      
      <p>
        If mammograms are much more effective than non-mammogram breast cancer exams, then we would expect to see additional deaths from breast cancer in the control group. On the other hand, if mammograms are not as effective as regular breast cancer exams, we would expect to see an increase in breast cancer deaths in the mammogram group.
      </p>
      
      <table xml:id="mammogramStudySummaryTable">
        <title>Summary results for breast cancer study.</title>
        <tabular>
          <row>
            <cell></cell>
            <cell></cell>
            <cell colspan="2" halign="center">Death from breast cancer?</cell>
          </row>
          <row bottom="minor">
            <cell></cell>
            <cell></cell>
            <cell>Yes</cell>
            <cell>No</cell>
          </row>
          <row>
            <cell>Mammogram</cell>
            <cell></cell>
            <cell>500</cell>
            <cell>44,425</cell>
          </row>
          <row>
            <cell>Control</cell>
            <cell></cell>
            <cell>505</cell>
            <cell>44,405</cell>
          </row>
        </tabular>
      </table>
      
      <exercise xml:id="ex-mammogram-experiment">
        <statement>
          <p>
            Is this study an experiment or an observational study?
          </p>
        </statement>
        <solution>
          <p>
            This is an experiment. Patients were randomized to receive mammograms or a standard breast cancer exam. We will be able to make causal conclusions based on this study.
          </p>
        </solution>
      </exercise>
      
      <exercise xml:id="htFormammogramStudySummaryTable">
        <statement>
          <p>
            Set up hypotheses to test whether there was a difference in breast cancer deaths in the mammogram and control groups.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: the breast cancer death rate for patients screened using mammograms is the same as the breast cancer death rate for patients in the control, <m>p_{mgm} - p_{ctrl} = 0</m>.
          </p>
          <p>
            <m>H_A</m>: the breast cancer death rate for patients screened using mammograms is different than the breast cancer death rate for patients in the control, <m>p_{mgm} - p_{ctrl} \neq 0</m>.
          </p>
        </solution>
      </exercise>
      
      <p>
        In Example<nbsp/><xref ref="condFormammogramStudySummaryTableNormalInference"/>, we will check the conditions for using a normal distribution to analyze the results of the study. The details are very similar to that of confidence intervals. However, when the null hypothesis is that <m>p_1 - p_2 = 0</m>, we use a special proportion called the <term>pooled proportion</term> to check the success-failure condition:
      </p>
      <md>
        <mrow>\hat{p}_{\textit{pooled}} \amp = \frac{\text{\# of patients who died from breast cancer in the entire study}}{\text{\# of patients in the entire study}}</mrow>
        <mrow>\amp = \frac{500 + 505}{500 + \text{44,425} + 505 + \text{44,405}}</mrow>
        <mrow>\amp = 0.0112</mrow>
      </md>
      <p>
        This proportion is an estimate of the breast cancer death rate across the entire study, and it's our best estimate of the proportions <m>p_{mgm}</m> and <m>p_{ctrl}</m> <em>if the null hypothesis is true that <m>p_{mgm} = p_{ctrl}</m></em>. We will also use this pooled proportion when computing the standard error.
      </p>
      
      <example xml:id="condFormammogramStudySummaryTableNormalInference">
        <statement>
          <p>
            Is it reasonable to model the difference in proportions using a normal distribution in this study?
          </p>
        </statement>
        <solution>
          <p>
            Because the patients are randomized, they can be treated as independent, both within and between groups. We also must check the success-failure condition for each group. Under the null hypothesis, the proportions <m>p_{mgm}</m> and <m>p_{ctrl}</m> are equal, so we check the success-failure condition with our best estimate of these values under <m>H_0</m>, the pooled proportion from the two samples, <m>\hat{p}_{\textit{pooled}} = 0.0112</m>:
          </p>
          <md>
            <mrow>\hat{p}_{\textit{pooled}} \times n_{mgm} \amp = 0.0112 \times \text{44,925} = 503</mrow>
            <mrow>(1 - \hat{p}_{\textit{pooled}}) \times n_{mgm} \amp = 0.9888 \times \text{44,925} = \text{44,422}</mrow>
            <mrow>\hat{p}_{\textit{pooled}} \times n_{ctrl} \amp = 0.0112 \times \text{44,910} = 503</mrow>
            <mrow>(1 - \hat{p}_{\textit{pooled}}) \times n_{ctrl} \amp = 0.9888 \times \text{44,910} = \text{44,407}</mrow>
          </md>
          <p>
            The success-failure condition is satisfied since all values are at least 10. With both conditions satisfied, we can safely model the difference in proportions using a normal distribution.
          </p>
        </solution>
      </example>
      
      <assemblage xml:id="assem-pooled-proportion">
        <title>Use the pooled proportion when <m>H_0</m> is <m>p_1 - p_2 = 0</m></title>
        <p>
          When the null hypothesis is that the proportions are equal, use the pooled proportion (<m>\hat{p}_{\textit{pooled}}</m>) to verify the success-failure condition and estimate the standard error:
        </p>
        <me>
          \hat{p}_{\textit{pooled}} = \frac{\text{number of ``successes''}}{\text{number of cases}} = \frac{\hat{p}_1 n_1 + \hat{p}_2 n_2}{n_1 + n_2}
        </me>
        <p>
          Here <m>\hat{p}_1 n_1</m> represents the number of successes in sample 1 since
        </p>
        <me>
          \hat{p}_1 = \frac{\text{number of successes in sample 1}}{n_1}
        </me>
        <p>
          Similarly, <m>\hat{p}_2 n_2</m> represents the number of successes in sample 2.
        </p>
      </assemblage>
      
      <p>
        In Example<nbsp/><xref ref="condFormammogramStudySummaryTableNormalInference"/>, the pooled proportion was used to check the success-failure condition.<fn>For an example of a two-proportion hypothesis test that does not require the success-failure condition to be met, see Section<nbsp/><xref ref="caseStudyMalariaVaccine"/>.</fn> In the next example, we see the second place where the pooled proportion comes into play: the standard error calculation.
      </p>
      
      <example xml:id="ex-mammogram-se">
        <statement>
          <p>
            Compute the point estimate of the difference in breast cancer death rates in the two groups, and use the pooled proportion <m>\hat{p}_{\textit{pooled}} = 0.0112</m> to calculate the standard error.
          </p>
        </statement>
        <solution>
          <p>
            The point estimate of the difference in breast cancer death rates is
          </p>
          <md>
            <mrow>\hat{p}_{mgm} - \hat{p}_{ctrl} \amp = \frac{500}{500 + 44,425} - \frac{505}{505 + 44,405}</mrow>
            <mrow>\amp = 0.01113 - 0.01125</mrow>
            <mrow>\amp = -0.00012</mrow>
          </md>
          <p>
            The breast cancer death rate in the mammogram group was 0.012% less than in the control group. Next, the standard error is calculated <em>using the pooled proportion</em>, <m>\hat{p}_{\textit{pooled}}</m>:
          </p>
          <md>
            <mrow>SE = \sqrt{\frac{\hat{p}_{\textit{pooled}}(1-\hat{p}_{\textit{pooled}})}{n_{mgm}} + \frac{\hat{p}_{\textit{pooled}}(1-\hat{p}_{\textit{pooled}})}{n_{ctrl}}} = 0.00070</mrow>
          </md>
        </solution>
      </example>
      
      <example xml:id="ex-mammogram-ht">
        <statement>
          <p>
            Using the point estimate <m>\hat{p}_{mgm} - \hat{p}_{ctrl} = -0.00012</m> and standard error <m>SE = 0.00070</m>, calculate a p-value for the hypothesis test and write a conclusion.
          </p>
        </statement>
        <solution>
          <p>
            Just like in past tests, we first compute a test statistic and draw a picture:
          </p>
          <md>
            <mrow>Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{-0.00012 - 0}{0.00070} = -0.17</mrow>
          </md>
          <figure xml:id="mammogramPValue">
            <caption>A normal distribution is shown centered at 0 with a standard deviation of 0.0007. The lower tail is shaded below -0.00012 and the upper tail is shaded above 0.00012. Visually, it looks like very roughly 90% of the area under the normal distribution is shaded.</caption>
            <image source="ch_inference_for_props/mammograms/mammogramPValue.pdf" width="45%"/>
          </figure>
          <p>
            The lower tail area is 0.4325, which we double to get the p-value: 0.8650. Because this p-value is larger than 0.05, we do not reject the null hypothesis. That is, the difference in breast cancer death rates is reasonably explained by chance, and we do not observe benefits or harm from mammograms relative to a regular breast exam.
          </p>
        </solution>
      </example>
      
      <p>
        Can we conclude that mammograms have no benefits or harm? Here are a few considerations to keep in mind when reviewing the mammogram study as well as any other medical study:
      </p>
      <ul>
        <li>
          We do not reject the null hypothesis, which means we don't have sufficient evidence to conclude that mammograms reduce or increase breast cancer deaths.
        </li>
        <li>
          If mammograms are helpful or harmful, the data suggest the effect isn't very large.
        </li>
        <li>
          Are mammograms more or less expensive than a non-mammogram breast exam? If one option is much more expensive than the other and doesn't offer clear benefits, then we should lean towards the less expensive option.
        </li>
        <li>
          The study's authors also found that mammograms led to overdiagnosis of breast cancer, which means some breast cancers were found (or thought to be found) but that these cancers would not cause symptoms during patients' lifetimes. That is, something else would kill the patient before breast cancer symptoms appeared. This means some patients may have been treated for breast cancer unnecessarily, and this treatment is another cost to consider. It is also important to recognize that overdiagnosis can cause unnecessary physical or emotional harm to patients.
        </li>
      </ul>
      <p>
        These considerations highlight the complexity around medical care and treatment recommendations. Experts and medical boards who study medical treatments use considerations like those above to provide their best recommendation based on the current evidence.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-more-2prop-ht">
      <title>More on 2-proportion hypothesis tests (special topic)</title>
      
      <p>
        When we conduct a 2-proportion hypothesis test, usually <m>H_0</m> is <m>p_1 - p_2 = 0</m>. However, there are rare situations where we want to check for some difference in <m>p_1</m> and <m>p_2</m> that is some value other than 0. For example, maybe we care about checking a null hypothesis where <m>p_1 - p_2 = 0.1</m>. In contexts like these, we generally use <m>\hat{p}_1</m> and <m>\hat{p}_2</m> to check the success-failure condition and construct the standard error.
      </p>
      
      <exercise xml:id="carWheelBladeManufacturer">
        <statement>
          <p>
            A quadcopter company is considering a new manufacturer for rotor blades. The new manufacturer would be more expensive, but they claim their higher-quality blades are more reliable, with 3% more blades passing inspection than their competitor. Set up appropriate hypotheses for the test.
          </p>
        </statement>
        <solution>
          <p>
            <m>H_0</m>: The higher-quality blades will pass inspection 3% more frequently than the standard-quality blades. <m>p_{highQ} - p_{standard} = 0.03</m>.
          </p>
          <p>
            <m>H_A</m>: The higher-quality blades will pass inspection some amount different than 3% more often than the standard-quality blades. <m>p_{highQ} - p_{standard} \neq 0.03</m>.
          </p>
        </solution>
      </exercise>
      
      <figure xml:id="quadcopter_david_j">
        <caption>A Phantom quadcopter. Photo by David J (http://flic.kr/p/oiWLNu). CC-BY 2.0 license. This photo has been cropped and a border has been added.</caption>
        <image source="ch_inference_for_props/quadcopter/quadcopter_david_j.jpg" width="60%"/>
      </figure>
      
      <example xml:id="qualityCtrlEngHypothesisEval">
        <statement>
          <p>
            The quality control engineer from Guided Practice<nbsp/><xref ref="carWheelBladeManufacturer"/> collects a sample of blades, examining 1000 blades from each company, and she finds that 899 blades pass inspection from the current supplier and 958 pass inspection from the prospective supplier. Using these data, evaluate the hypotheses from Guided Practice<nbsp/><xref ref="carWheelBladeManufacturer"/> with a significance level of 5%.
          </p>
        </statement>
        <solution>
          <p>
            First, we check the conditions. The sample is not necessarily random, so to proceed we must assume the blades are all independent; for this sample we will suppose this assumption is reasonable, but the engineer would be more knowledgeable as to whether this assumption is appropriate. The success-failure condition also holds for each sample. Thus, the difference in sample proportions, <m>0.958 - 0.899 = 0.059</m>, can be said to come from a nearly normal distribution.
          </p>
          <p>
            The standard error is computed using the two sample proportions since we do not use a pooled proportion for this context:
          </p>
          <md>
            <mrow>SE = \sqrt{\frac{0.958(1-0.958)}{1000} + \frac{0.899(1-0.899)}{1000}} = 0.0114</mrow>
          </md>
          <p>
            In this hypothesis test, because the null is that <m>p_1 - p_2 = 0.03</m>, the sample proportions were used for the standard error calculation rather than a pooled proportion.
          </p>
          <p>
            Next, we compute the test statistic and use it to find the p-value, which is depicted in <xref ref="bladesTwoSampleHTPValueQC"/>.
          </p>
          <md>
            <mrow>Z = \frac{\text{point estimate} - \text{null value}}{SE} = \frac{0.059 - 0.03}{0.0114} = 2.54</mrow>
          </md>
          <p>
            Using a standard normal distribution for this test statistic, we identify the right tail area as 0.006, and we double it to get the p-value: 0.012. We reject the null hypothesis because 0.012 is less than 0.05. Since we observed a larger-than-3% increase in blades that pass inspection, we have statistically significant evidence that the higher-quality blades pass inspection <em>more than</em> 3% as often as the currently used blades, exceeding the company's claims.
          </p>
        </solution>
      </example>
      
      <figure xml:id="bladesTwoSampleHTPValueQC">
        <caption>Distribution of the test statistic if the null hypothesis was true. The p-value is represented by the shaded areas.</caption>
        <image source="ch_inference_for_props/bladesTwoSampleHTPValueQC.pdf" width="45%"/>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-se-formula-special">
      <title>Examining the standard error formula (special topic)</title>
      
      <p>
        This subsection covers more theoretical topics that offer deeper insights into the origins of the standard error formula for the difference of two proportions. Ultimately, all of the standard error formulas we encounter in this chapter and in Chapter<nbsp/><xref ref="ch_inference_for_means"/> can be derived from the probability principles of Section<nbsp/><xref ref="randomVariablesSection"/>.
      </p>
      
      <p>
        The formula for the standard error of the difference in two proportions can be deconstructed into the formulas for the standard errors of the individual sample proportions. Recall that the standard error of the individual sample proportions <m>\hat{p}_1</m> and <m>\hat{p}_2</m> are
      </p>
      <md>
        <mrow>SE_{\hat{p}_1} = \sqrt{\frac{{p}_1 (1 - {p}_1)}{n_1}} \qquad SE_{\hat{p}_2} = \sqrt{\frac{{p}_2 (1 - {p}_2)}{n_2}}</mrow>
      </md>
      <p>
        The standard error of the difference of two sample proportions can be deconstructed from the standard errors of the separate sample proportions:
      </p>
      <md>
        <mrow>SE_{\hat{p}_{1} - \hat{p}_{2}} = \sqrt{SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2} = \sqrt{\frac{{p}_1 (1 - {p}_1)}{n_1} + \frac{{p}_2 (1 - {p}_2)}{n_2}}</mrow>
      </md>
      <p>
        This special relationship follows from probability theory.
      </p>
      
      <exercise xml:id="derivingSEForDiffOfTwoMeansExercise">
        <statement>
          <p>
            Prerequisite: Section<nbsp/><xref ref="randomVariablesSection"/>. We can rewrite the equation above in a different way:
          </p>
          <me>
            SE_{\hat{p}_{1} - \hat{p}_{2}}^2 = SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2
          </me>
          <p>
            Explain where this formula comes from using the formula for the variability of the sum of two random variables.
          </p>
        </statement>
        <solution>
          <p>
            The standard error squared represents the variance of the estimate. If <m>X</m> and <m>Y</m> are two random variables with variances <m>\sigma_x^2</m> and <m>\sigma_y^2</m>, then the variance of <m>X - Y</m> is <m>\sigma_x^2 + \sigma_y^2</m>. Likewise, the variance corresponding to <m>\hat{p}_1 - \hat{p}_2</m> is <m>\sigma_{\hat{p}_1}^2 + \sigma_{\hat{p}_2}^2</m>. Because <m>\sigma_{\hat{p}_1}^2</m> and <m>\sigma_{\hat{p}_2}^2</m> are just another way of writing <m>SE_{\hat{p}_1}^2</m> and  <m>SE_{\hat{p}_2}^2</m>, the variance associated with <m>\hat{p}_1 - \hat{p}_2</m> may be written as <m>SE_{\hat{p}_1}^2 + SE_{\hat{p}_2}^2</m>.
          </p>
        </solution>
      </exercise>
    </subsection>
    
  </section>
  
  <!-- Section 7.3: Testing for goodness of fit using chi-square -->
  <section xml:id="sec-chi-square-gof">
    <title>Testing for Goodness of Fit Using Chi-Square</title>
    
    <introduction>
      <p>
        Sometimes we want to evaluate whether the observed distribution of a categorical variable
        matches a hypothesized distribution. For example: Does the distribution of blood types in a
        sample match the known distribution in the general population? Do observed frequencies of
        outcomes match those expected if a die is fair? These questions can be answered using a
        <term>chi-square goodness of fit test</term>.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-gof-test-intro">
      <title>Goodness of Fit Test</title>
      
      <p>
        In a goodness of fit test, we compare observed counts to expected counts under a null
        hypothesis. The test statistic measures how far the observed counts are from the expected counts.
      </p>
      
      <definition xml:id="def-chi-square-statistic">
        <statement>
          <p>
            The <term>chi-square test statistic</term> for goodness of fit is:
          </p>
          <md>
            \chi^2 = \sum \frac{(\text{observed} - \text{expected})^2}{\text{expected}} = \sum \frac{(O - E)^2}{E}
          </md>
          <p>
            where the sum is taken over all categories.
          </p>
        </statement>
      </definition>
      
      <p>
        The chi-square statistic measures the total deviation between observed and expected counts.
        Large values of <m>\chi^2</m> indicate a poor fit between the data and the null hypothesis.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-distribution">
      <title>The Chi-Square Distribution</title>
      
      <p>
        When the sample size is large enough, the chi-square test statistic follows a
        <term>chi-square distribution</term>.
      </p>
      
      <definition xml:id="def-chi-square-dist">
        <statement>
          <p>
            The <term>chi-square distribution</term> is a right-skewed distribution that starts at
            zero. It has one parameter: <term>degrees of freedom (df)</term>. For a goodness of fit
            test with <m>k</m> categories:
          </p>
          <md>
            df = k - 1
          </md>
        </statement>
      </definition>
      
      <p>
        <alert>Conditions for the chi-square goodness of fit test:</alert>
      </p>
      
      <ol>
        <li><alert>Independence:</alert> The observations must be independent.</li>
        <li><alert>Sample size:</alert> Each expected count must be at least 5.</li>
      </ol>
      
      <p>
        The p-value for a chi-square test is always found in the upper tail of the chi-square
        distribution, since large values of <m>\chi^2</m> provide evidence against <m>H_0</m>.
      </p>
    </subsection>
  </section>
  
  <!-- Section 7.4: Testing for independence in two-way tables -->
  <section xml:id="sec-chi-square-independence">
    <title>Testing for Independence in Two-Way Tables</title>
    
    <introduction>
      <p>
        A two-way table (also called a <term>contingency table</term>) summarizes data for two
        categorical variables. We often want to know: Are these two variables independent, or is
        there an association between them?
      </p>
    </introduction>
    
    <subsection xml:id="subsec-two-way-tables">
      <title>Two-Way Tables and Expected Counts</title>
      
      <p>
        In a two-way table, we organize data by two categorical variables. To test for independence,
        we compare observed counts to expected counts under the assumption that the variables are
        independent.
      </p>
      
      <assemblage xml:id="assem-expected-counts">
        <title>Computing Expected Counts</title>
        <p>
          If two variables are independent, the expected count for a cell in row <m>i</m> and
          column <m>j</m> is:
        </p>
        <md>
          E_{ij} = \frac{(\text{row } i \text{ total}) \times (\text{column } j \text{ total})}{\text{table total}}
        </md>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-test-independence">
      <title>The Chi-Square Test for Independence</title>
      
      <p>
        The chi-square test for independence uses the same test statistic as the goodness of fit test:
      </p>
      
      <md>
        \chi^2 = \sum_{all\text{ }cells} \frac{(O - E)^2}{E}
      </md>
      
      <p>
        However, the degrees of freedom are calculated differently:
      </p>
      
      <md>
        df = (\text{number of rows} - 1) \times (\text{number of columns} - 1)
      </md>
      
      <p>
        <alert>Hypotheses:</alert>
      </p>
      
      <ul>
        <li><m>H_0</m>: The two variables are independent.</li>
        <li><m>H_A</m>: The two variables are not independent (they are associated).</li>
      </ul>
      
      <p>
        <alert>Conditions:</alert>
      </p>
      
      <ol>
        <li><alert>Independence:</alert> Each case that contributes a count to the table must be
            independent of all other cases.</li>
        <li><alert>Sample size:</alert> Each expected count must be at least 5.</li>
      </ol>
      
      <important>
        <p>
          The chi-square test for independence tells us <em>whether</em> there is an association,
          but it doesn't tell us the nature or strength of that association. If the test is
          significant, examine the table and consider computing row or column proportions to
          understand the relationship.
        </p>
      </important>
    </subsection>
    
    <subsection xml:id="subsec-chi-square-limitations">
      <title>Limitations of Chi-Square Tests</title>
      
      <p>
        Important considerations when using chi-square tests:
      </p>
      
      <ul>
        <li>Chi-square tests can only establish whether an association exists; they do not
            determine causation.</li>
        <li>The test requires all expected counts to be at least 5. If this condition is not met,
            consider combining categories or using an alternative test (such as Fisher's exact test).</li>
        <li>Large sample sizes can make even trivial differences statistically significant. Always
            consider practical significance alongside statistical significance.</li>
        <li>Chi-square tests work with counts, not percentages or proportions. Make sure your data
            are in the correct form.</li>
      </ul>
    </subsection>
  </section>
  
  <!-- Section 7.5: Chapter review -->
  <section xml:id="sec-ch07-review">
    <title>Chapter 7 Review Exercises</title>
    
    <p>
      This chapter covered inference for categorical data. Key concepts include:
    </p>
    
    <ul>
      <li>Confidence intervals and hypothesis tests for a single proportion</li>
      <li>Sample size calculations for proportions</li>
      <li>Comparing two proportions using confidence intervals and hypothesis tests</li>
      <li>The pooled proportion for hypothesis testing</li>
      <li>Chi-square goodness of fit tests for comparing observed and expected distributions</li>
      <li>Chi-square tests for independence in two-way tables</li>
      <li>Computing expected counts and degrees of freedom for chi-square tests</li>
    </ul>
    
    <p>
      Additional exercises for practicing these concepts are available in the accompanying
      exercise materials.
    </p>
  </section>
</chapter>
