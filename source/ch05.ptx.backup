<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="ch-foundations-for-inference" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Foundations for Inference</title>
  
  <introduction>
    <p>
      Statistical inference is primarily concerned with understanding and quantifying the
      uncertainty of parameter estimates. While the equations and details change depending on
      the setting, the foundations for inference are the same throughout all of statistics.
    </p>
    
    <p>
      We start with a familiar topic: the idea of using a sample proportion to estimate
      a population proportion. Next, we create what's called a <term>confidence interval</term>,
      which is a range of plausible values where we may find the true population value.
      Finally, we introduce the <term>hypothesis testing framework</term>, which allows us to
      formally evaluate claims about the population, such as whether a survey provides strong
      evidence that a candidate has the support of a majority of the voting population.
    </p>
  </introduction>

  <!-- Section 5.1: Point estimates and sampling variability -->
  <section xml:id="sec-point-estimates">
    <title>Point Estimates and Sampling Variability</title>
    
    <introduction>
      <p>
        Companies such as Pew Research frequently conduct polls as a way to understand the
        state of public opinion or knowledge on many topics, including politics, scientific
        understanding, brand recognition, and more. The ultimate goal in taking a poll is
        generally to use the responses to estimate the opinion or knowledge of the broader
        population.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-point-estimates-error">
      <title>Point Estimates and Error</title>
      
      <p>
        Suppose a poll suggested the US President's approval rating is 45%. We would consider
        45% to be a <term>point estimate</term> of the approval rating we might see if we
        collected responses from the entire population. This entire-population response
        proportion is generally referred to as the <term>parameter of interest</term>.
      </p>
      
      <p>
        When the parameter is a proportion, it is often denoted by <m>p</m>, and we often
        refer to the sample proportion as <m>\hat{p}</m> (pronounced <em>p-hat</em>). Unless
        we collect responses from every individual in the population, <m>p</m> remains
        unknown, and we use <m>\hat{p}</m> as our estimate of <m>p</m>. The difference we
        observe from the poll versus the parameter is called the <term>error</term> in the
        estimate.
      </p>
      
      <p>
        Generally, the error consists of two aspects: <term>sampling error</term> and
        <term>bias</term>.
      </p>
      
      <definition xml:id="def-sampling-error">
        <statement>
          <p>
            <term>Sampling error</term>, sometimes called <em>sampling uncertainty</em>,
            describes how much an estimate will tend to vary from one sample to the next.
            For instance, the estimate from one sample might be 1% too low while in another
            it may be 3% too high. The <term>sample size</term> is often represented by the
            letter <m>n</m>.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-bias">
        <statement>
          <p>
            <term>Bias</term> describes a systematic tendency to over- or under-estimate
            the true population value. We try to minimize bias through thoughtful data
            collection procedures.
          </p>
        </statement>
      </definition>
    </subsection>
    
    <subsection xml:id="subsec-variability-point-estimate">
      <title>Understanding the Variability of a Point Estimate</title>
      
      <p>
        To understand how a sample proportion behaves, consider a scenario where the
        proportion of American adults who support expanding solar energy is <m>p = 0.88</m>.
        If we were to take a poll of 1000 American adults on this topic, how close might we
        expect the sample proportion to be to 0.88?
      </p>
      
      <p>
        We can simulate responses we would get from a simple random sample of 1000 American
        adults through the following steps:
      </p>
      
      <ol>
        <li>Create a set of entries representing all American adults, where 88% say "support"
            and 12% say "not".</li>
        <li>Mix up the entries and pull out 1000 entries to represent our sample.</li>
        <li>Compute the fraction that say "support".</li>
      </ol>
      
      <p>
        If we conduct this simulation 10,000 times, we create a <term>sampling distribution</term>
        of the sample proportions. <xref ref="fig-sampling-distribution-solar"/> shows a histogram
        of the results from such a simulation.
      </p>
      
      <figure xml:id="fig-sampling-distribution-solar">
        <caption>A histogram of 10,000 sample proportions, where each sample includes 1,000 respondents from a population where <m>p = 0.88</m>.</caption>
        <image source="images/ch_foundations_for_inf/figures/sampling_10k_prop_88p/sampling_10k_prop_88p.pdf" width="70%">
          <description>Histogram showing distribution of sample proportions centered at 0.88</description>
        </image>
      </figure>
      
      <p>
        This distribution has important characteristics:
      </p>
      
      <ul>
        <li><strong>Center:</strong> The center of the distribution equals the population proportion, <m>p = 0.88</m>.</li>
        <li><strong>Spread:</strong> The standard deviation, which describes the typical deviation from the mean,
            is called the <term>standard error (SE)</term>. For this simulation, <m>SE = 0.0103</m>.</li>
        <li><strong>Shape:</strong> The distribution is approximately normal (bell-shaped).</li>
      </ul>
      
      <assemblage xml:id="note-standard-error-vs-sd">
        <title>Standard error versus standard deviation</title>
        <p>
          The term <term>standard error</term> refers to the standard deviation associated with
          an estimate. It describes the typical deviation we expect to see in estimates from one
          sample to another. The term <term>standard deviation</term> refers to the variability
          in the data or population.
        </p>
      </assemblage>
      
      <p>
        <xref ref="fig-normal-approximation-solar"/> shows the normal approximation to the
        sampling distribution, illustrating that about 95% of the sample proportions fall
        within 2 standard errors of the true proportion.
      </p>
      
      <figure xml:id="fig-normal-approximation-solar">
        <caption>The sampling distribution from <xref ref="fig-sampling-distribution-solar"/>, shown with its mean and standard error, and the normal curve.</caption>
        <image source="images/ch_foundations_for_inf/figures/p-hat_from_86_and_90/p-hat_from_86_and_90.pdf" width="70%">
          <description>Normal distribution with shaded middle region showing 95% of values</description>
        </image>
      </figure>
      
      <important>
        <p>
          Sampling distributions are never observed in practice, but we keep them in mind
          as they help us understand and characterize the point estimates we do observe.
        </p>
      </important>
    </subsection>
    
    <subsection xml:id="subsec-central-limit-theorem">
      <title>Central Limit Theorem</title>
      
      <p>
        The examples in the previous subsection highlight three important properties of the
        sampling distribution of a sample proportion:
      </p>
      
      <ol>
        <li>The mean of the sampling distribution is <m>p</m>.</li>
        <li>The standard deviation of the sampling distribution, called the standard error,
            can be calculated as <m>SE = \sqrt{\frac{p(1-p)}{n}}</m>.</li>
        <li>When the sample size is sufficiently large, the sampling distribution is
            approximately normal.</li>
      </ol>
      
      <theorem xml:id="thm-central-limit-theorem">
        <title>Central Limit Theorem for proportions</title>
        <statement>
          <p>
            When observations are independent and the sample size is sufficiently large,
            the sample proportion <m>\hat{p}</m> will tend to follow a normal distribution with:
          </p>
          <md>
            <mrow>\text{Mean:}\amp\ \mu_{\hat{p}} = p</mrow>
            <mrow>\text{Standard Error:}\amp\ SE_{\hat{p}} = \sqrt{\frac{p(1-p)}{n}}</mrow>
          </md>
        </statement>
      </theorem>
      
      <p>
        The Central Limit Theorem is incredibly important and provides a foundation for much
        of statistics. Be mindful of the two technical conditions:
      </p>
      
      <ol>
        <li><strong>Independence</strong>: The observations must be independent. This is
            satisfied for a random sample from a population.</li>
        <li><strong>Success-failure condition</strong>: The sample size must be sufficiently
            large. We consider the sample size large enough when <m>np \geq 10</m> and
            <m>n(1-p) \geq 10</m>.</li>
      </ol>
      
      <example xml:id="ex-se-calculation">
        <title>Computing mean and standard error</title>
        <statement>
          <p>
            Compute the theoretical mean and standard error of <m>\hat{p}</m> when
            <m>p = 0.88</m> and <m>n = 1000</m>, according to the Central Limit Theorem.
          </p>
        </statement>
        <solution>
          <p>
            The mean of <m>\hat{p}</m> is simply the population proportion:
            <me>\mu_{\hat{p}} = 0.88</me>
          </p>
          <p>
            The standard error of <m>\hat{p}</m> is calculated using:
            <md>
              <mrow>SE_{\hat{p}} \amp= \sqrt{\frac{p(1-p)}{n}}</mrow>
              <mrow>\amp= \sqrt{\frac{0.88 \times 0.12}{1000}}</mrow>
              <mrow>\amp= 0.0103</mrow>
            </md>
          </p>
        </solution>
      </example>
      
      <p>
        <xref ref="fig-clt-grid"/> shows how the sampling distribution changes with different
        values of <m>p</m> and <m>n</m>. Notice that:
      </p>
      
      <ul>
        <li>Larger sample sizes produce narrower, more precise distributions.</li>
        <li>The distribution becomes more symmetric when <m>p</m> is near 0.5.</li>
        <li>All distributions are centered at their respective <m>p</m> values.</li>
      </ul>
      
      <figure xml:id="fig-clt-grid">
        <caption>Sampling distributions for different values of <m>p</m> and <m>n</m>.</caption>
        <image source="images/ch_foundations_for_inf/figures/clt_prop_grid/clt_prop_grid_1.pdf" width="80%">
          <description>Grid of sampling distributions showing effect of sample size and proportion</description>
        </image>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-clt-real-world">
      <title>Applying the Central Limit Theorem to Real-World Settings</title>
      
      <p>
        In practice, we don't know the population proportion <m>p</m>, which creates a
        challenge: we can't calculate the standard error exactly because it requires <m>p</m>.
        However, we can use the <term>substitution approximation</term> (also called the
        <em>plug-in principle</em>) where we use <m>\hat{p}</m> in place of <m>p</m>:
      </p>
      
      <md>
        <mrow>SE_{\hat{p}} \approx \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</mrow>
      </md>
      
      <p>
        This approximation works well when the sample size is reasonably large. We also
        use <m>\hat{p}</m> in place of <m>p</m> when checking the success-failure condition
        in real applications.
      </p>
      
      <assemblage xml:id="conditions-for-CLT">
        <title>Conditions for using the Central Limit Theorem for proportions</title>
        <p>
          To apply the Central Limit Theorem for a sample proportion, the following
          conditions should be met:
        </p>
        <ol>
          <li><strong>Independence</strong>: The observations are independent, typically
              satisfied by random sampling or random assignment.</li>
          <li><strong>Success-failure condition</strong>: We expect at least 10 successes
              and 10 failures in our sample: <m>n\hat{p} \geq 10</m> and
              <m>n(1-\hat{p}) \geq 10</m>.</li>
        </ol>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-extending-framework">
      <title>Extending the Framework for Other Statistics</title>
      
      <p>
        The strategy of using a sample statistic to estimate a parameter is quite common and
        can be applied to other statistics besides a proportion. For instance, to estimate
        the average salary for graduates from a particular college, we could survey a random
        sample of recent graduates and use the sample mean <m>\bar{x}</m> to estimate the
        population mean <m>\mu</m>.
      </p>
      
      <p>
        The principles and general ideas are the same across different contexts:
      </p>
      
      <ul>
        <li>A point estimate from a sample is used to estimate an unknown parameter.</li>
        <li>The sampling distribution describes how the estimate varies from sample to sample.</li>
        <li>The standard error quantifies the typical deviation in the estimates.</li>
        <li>Under certain conditions, the Central Limit Theorem tells us the sampling
            distribution is approximately normal.</li>
      </ul>
      
      <p>
        While this chapter emphasizes a single proportion context, these methods will be
        applied to many different contexts throughout this book.
      </p>
    </subsection>
    
    <exercises>
      <title>Section 5.1 Exercises</title>
      
      <exercise xml:id="ex-identify-parameter-1">
        <statement>
          <p>
            For each of the following situations, state whether the parameter of interest
            is a mean or a proportion.
          </p>
          <ol>
            <li>In a survey, one hundred college students are asked how many hours per week
                they spend on the Internet.</li>
            <li>In a survey, one hundred college students are asked whether or not they
                cited information from Wikipedia in their papers.</li>
            <li>In a sample of one hundred recent college graduates, it is found that 85
                percent expect to get a job within one year of their graduation date.</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-quality-control">
        <statement>
          <p>
            As part of a quality control process for computer chips, an engineer at a
            factory randomly samples 212 chips during a week of production to test the
            current rate of chips with severe defects. She finds that 27 of the chips
            are defective.
          </p>
          <ol>
            <li>What population is under consideration in the data set?</li>
            <li>What parameter is being estimated?</li>
            <li>What is the point estimate for the parameter?</li>
            <li>What is the name of the statistic we use to measure the uncertainty of
                the point estimate?</li>
            <li>Compute this value for this context.</li>
          </ol>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 5.2: Confidence intervals for a proportion -->
  <section xml:id="sec-confidence-intervals">
    <title>Confidence Intervals for a Proportion</title>
    
    <introduction>
      <p>
        The sample proportion <m>\hat{p}</m> provides a single plausible value for the
        population proportion <m>p</m>. However, the sample proportion isn't perfect and
        will have some standard error associated with it. When stating an estimate for the
        population proportion, it is better practice to provide a plausible range of values
        instead of supplying just the point estimate.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-capturing-parameter">
      <title>Capturing the Population Parameter</title>
      
      <p>
        A <term>confidence interval</term> is a range of plausible values where we are
        likely to find the population parameter. Using a confidence interval is like fishing
        with a net instead of a spear: we have a good chance of catching the fish.
      </p>
      
      <p>
        If we took many samples and built a confidence interval from each sample using the
        same method, we'd expect that some of the intervals would contain the parameter and
        some wouldn't. A <em>95% confidence interval</em> means that if we were to repeat
        the process many times, about 95% of the intervals would contain the true parameter.
      </p>
      
      <figure xml:id="fig-25-confidence-intervals">
        <caption>25 confidence intervals constructed from 25 different samples. The red intervals do not contain the true population proportion <m>p</m>.</caption>
        <image source="images/ch_foundations_for_inf/figures/95PercentConfidenceInterval/95PercentConfidenceInterval.pdf" width="75%">
          <description>Visualization of 25 confidence intervals, most containing the true parameter</description>
        </image>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-95-ci">
      <title>Constructing a 95% Confidence Interval</title>
      
      <p>
        Our sample proportion <m>\hat{p}</m> is the most plausible value of the population
        proportion, so it makes sense to build a confidence interval around this point estimate.
        The standard error provides a guide for how large we should make the confidence interval.
      </p>
      
      <p>
        In a normal distribution, approximately 95% of the data is within 1.96 standard
        deviations of the mean. Using this principle, we can construct a confidence interval
        that extends 1.96 standard errors from the sample proportion:
      </p>
      
      <md>
        <mrow>\text{95% CI} \amp= \text{point estimate} \pm 1.96 \times SE</mrow>
        <mrow>\amp= \hat{p} \pm 1.96 \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</mrow>
      </md>
      
      <definition xml:id="def-95-ci">
        <title>95% Confidence Interval for a proportion</title>
        <statement>
          <p>
            A 95% confidence interval for a population proportion is:
          </p>
          <me>\hat{p} \pm 1.96 \times SE_{\hat{p}}</me>
          <p>
            where <m>SE_{\hat{p}} = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</m>.
          </p>
          <p>
            This confidence interval accounts for sampling error but not bias.
          </p>
        </statement>
      </definition>
      
      <example xml:id="ex-solar-95-ci">
        <title>95% CI for solar energy support</title>
        <statement>
          <p>
            In a Pew Research poll, 887 out of 1000 American adults (88.7%) supported
            expanding the use of solar energy. Compute and interpret a 95% confidence
            interval for the population proportion.
          </p>
        </statement>
        <solution>
          <p>
            First, we verify the conditions. The observations are from a random sample,
            so they are independent. We check the success-failure condition:
            <md>
              <mrow>n\hat{p} \amp= 1000 \times 0.887 = 887 \geq 10</mrow>
              <mrow>n(1-\hat{p}) \amp= 1000 \times 0.113 = 113 \geq 10</mrow>
            </md>
            Both are greater than 10, so the conditions are met.
          </p>
          <p>
            The standard error is:
            <md>
              <mrow>SE_{\hat{p}} \amp= \sqrt{\frac{0.887 \times 0.113}{1000}}</mrow>
              <mrow>\amp= 0.0101</mrow>
            </md>
          </p>
          <p>
            The 95% confidence interval is:
            <md>
              <mrow>0.887 \pm 1.96 \times 0.0101 \amp= 0.887 \pm 0.0198</mrow>
              <mrow>\amp= (0.8672, 0.9068)</mrow>
            </md>
          </p>
          <p>
            <strong>Interpretation:</strong> We are 95% confident that between 86.7% and
            90.7% of American adults support expanding the use of solar energy.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-changing-confidence">
      <title>Changing the Confidence Level</title>
      
      <p>
        We can create confidence intervals with different confidence levels. The multiplier
        we use depends on how confident we want to be:
      </p>
      
      <table xml:id="table-z-star-values">
        <title>Common confidence levels and corresponding <m>z^*</m> values</title>
        <tabular>
          <row header="yes">
            <cell>Confidence Level</cell>
            <cell><m>z^*</m> value</cell>
          </row>
          <row>
            <cell>90%</cell>
            <cell>1.65</cell>
          </row>
          <row>
            <cell>95%</cell>
            <cell>1.96</cell>
          </row>
          <row>
            <cell>99%</cell>
            <cell>2.58</cell>
          </row>
        </tabular>
      </table>
      
      <definition xml:id="def-general-ci">
        <title>General form of a confidence interval</title>
        <statement>
          <p>
            For a point estimate that closely follows a normal model with standard error
            <m>SE</m>, a confidence interval for the population parameter is:
          </p>
          <me>\text{point estimate} \pm z^* \times SE</me>
          <p>
            where <m>z^*</m> corresponds to the confidence level selected.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-margin-of-error">
        <title>Margin of Error</title>
        <statement>
          <p>
            In a confidence interval, <m>z^* \times SE</m> is called the <term>margin of error</term>.
            It represents how far above and below the point estimate the confidence interval extends.
          </p>
        </statement>
      </definition>
      
      <figure xml:id="fig-choosing-z-star">
        <caption>The area between <m>-z^*</m> and <m>z^*</m> in the standard normal distribution for common confidence levels.</caption>
        <image source="images/ch_foundations_for_inf/figures/choosingZForCI/choosingZForCI.pdf" width="70%">
          <description>Normal curve showing z-star values for different confidence levels</description>
        </image>
      </figure>
    </subsection>
    
    <subsection xml:id="subsec-ci-procedure">
      <title>Confidence Interval Procedure for a Single Proportion</title>
      
      <assemblage xml:id="ci-procedure">
        <title>Four-step confidence interval procedure</title>
        <ol>
          <li><strong>Prepare:</strong> Identify <m>\hat{p}</m> and <m>n</m>, and determine
              what confidence level you wish to use.</li>
          <li><strong>Check:</strong> Verify the conditions to ensure <m>\hat{p}</m> is
              nearly normal. For one-proportion confidence intervals, use <m>\hat{p}</m>
              in place of <m>p</m> to check the success-failure condition.</li>
          <li><strong>Calculate:</strong> If the conditions hold, compute <m>SE</m> using
              <m>\hat{p}</m>, find <m>z^*</m>, and construct the interval.</li>
          <li><strong>Conclude:</strong> Interpret the confidence interval in the context
              of the problem.</li>
        </ol>
      </assemblage>
    </subsection>
    
    <subsection xml:id="subsec-more-case-studies">
      <title>More Case Studies</title>
      
      <p>
        Let's apply the confidence interval procedure to two more real-world examples
        to solidify our understanding.
      </p>
      
      <example xml:id="ex-ebola-quarantine">
        <title>Ebola quarantine support in New York</title>
        <statement>
          <p>
            In New York City on October 23, 2014, a doctor who had recently been treating
            Ebola patients in Guinea went to the hospital with a slight fever and was
            subsequently diagnosed with Ebola. Soon thereafter, an NBC 4 New York/The Wall
            Street Journal/Marist Poll found that 82% of New Yorkers favored a "mandatory
            21-day quarantine for anyone who has come in contact with an Ebola patient."
            This poll included responses of 1,042 New York adults between October 26-28, 2014.
          </p>
          <ol>
            <li>What is the point estimate, and is it reasonable to use a normal distribution
                to model it?</li>
            <li>Estimate the standard error of <m>\hat{p} = 0.82</m>.</li>
            <li>Construct a 95% confidence interval for the proportion of New York adults
                who supported the quarantine policy.</li>
          </ol>
        </statement>
        <solution>
          <ol>
            <li>
              <p>
                The point estimate, based on a sample of size <m>n = 1042</m>, is
                <m>\hat{p} = 0.82</m>. To check whether <m>\hat{p}</m> can be reasonably
                modeled using a normal distribution, we check independence (the poll is
                based on a simple random sample) and the success-failure condition:
                <md>
                  <mrow>n\hat{p} \amp= 1042 \times 0.82 = 854 \geq 10 \checkmark</mrow>
                  <mrow>n(1-\hat{p}) \amp= 1042 \times 0.18 = 188 \geq 10 \checkmark</mrow>
                </md>
                With the conditions met, we can model <m>\hat{p}</m> using a normal
                distribution.
              </p>
            </li>
            <li>
              <p>
                Using the substitution approximation <m>p \approx \hat{p} = 0.82</m>:
                <md>
                  <mrow>SE_{\hat{p}} \amp= \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</mrow>
                  <mrow>\amp= \sqrt{\frac{0.82 \times 0.18}{1042}}</mrow>
                  <mrow>\amp= 0.012</mrow>
                </md>
              </p>
            </li>
            <li>
              <p>
                Using <m>SE = 0.012</m>, <m>\hat{p} = 0.82</m>, and <m>z^* = 1.96</m>:
                <md>
                  <mrow>0.82 \pm 1.96 \times 0.012 \amp= 0.82 \pm 0.024</mrow>
                  <mrow>\amp= (0.796, 0.844)</mrow>
                </md>
                <strong>Interpretation:</strong> We are 95% confident that between 79.6%
                and 84.4% of New York adults in October 2014 supported a quarantine for
                anyone who had come into contact with an Ebola patient.
              </p>
            </li>
          </ol>
        </solution>
      </example>
      
      <exercise xml:id="ex-wind-turbines-guided">
        <title>Wind turbine support</title>
        <statement>
          <p>
            In the same Pew Research poll about solar energy, they also inquired about
            other forms of energy, and 84.8% of the 1,000 respondents supported expanding
            the use of wind turbines.
          </p>
          <ol>
            <li>Is it reasonable to model the proportion of US adults who support expanding
                wind turbines using a normal distribution?</li>
            <li>Create a 99% confidence interval for the level of American support for
                expanding the use of wind turbines for power generation.</li>
          </ol>
        </statement>
        <hint>
          <p>
            For part (b), recall that for a 99% confidence interval, <m>z^* = 2.58</m>.
          </p>
        </hint>
        <answer>
          <ol>
            <li>
              <p>
                Yes. The survey was a random sample and the success-failure counts are
                both <m>\geq 10</m>: <m>n\hat{p} = 1000 \times 0.848 = 848</m> and
                <m>n(1-\hat{p}) = 1000 \times 0.152 = 152</m>.
              </p>
            </li>
            <li>
              <p>
                The standard error is:
                <me>SE = \sqrt{\frac{0.848 \times 0.152}{1000}} = 0.0114</me>
                The 99% confidence interval is:
                <md>
                  <mrow>0.848 \pm 2.58 \times 0.0114 \amp= 0.848 \pm 0.029</mrow>
                  <mrow>\amp= (0.819, 0.877)</mrow>
                </md>
                We are 99% confident that between 81.9% and 87.7% of American adults
                support expanding the use of wind turbines.
              </p>
            </li>
          </ol>
        </answer>
      </exercise>
    </subsection>
    
    <subsection xml:id="subsec-interpreting-ci">
      <title>Interpreting Confidence Intervals</title>
      
      <p>
        When interpreting a confidence interval, remember:
      </p>
      
      <ul>
        <li>The statement is about the <em>population parameter</em>, not about individual
            observations or future samples.</li>
        <li>A 95% confidence interval means that if we repeated the sampling process many
            times, about 95% of the intervals would contain the true parameter.</li>
        <li>We don't know if our particular interval contains the parameter, but we can
            be 95% confident that it does.</li>
      </ul>
      
      <important>
        <p>
          Remember that these methods only address sampling error, not bias. If data is
          collected in a way that systematically under- or over-estimates the population
          parameter, these techniques will not fix that problem.
        </p>
      </important>
    </subsection>
    
    <exercises>
      <title>Section 5.2 Exercises</title>
      
      <exercise xml:id="ex-ebola-ci">
        <statement>
          <p>
            In response to the Ebola outbreak in 2014, a poll found that 82% of 1,042
            American adults supported mandatory quarantine for anyone who had contact
            with an Ebola patient. Construct and interpret a 95% confidence interval
            for the proportion of all American adults who supported this policy.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-wind-turbines-99-ci">
        <statement>
          <p>
            In a survey of 1,000 adults, 848 supported expanding the use of wind energy.
            Construct and interpret a 99% confidence interval for the proportion of all
            adults who support expanding wind energy.
          </p>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 5.3: Hypothesis testing for a proportion -->
  <section xml:id="sec-hypothesis-testing">
    <title>Hypothesis Testing for a Proportion</title>
    
    <introduction>
      <p>
        The hypothesis testing framework is used to rigorously evaluate competing ideas and
        claims. In this section, we'll explore how to formally test claims about population
        proportions using data from samples.
      </p>
    </introduction>
    
    <subsection xml:id="subsec-ht-framework">
      <title>Hypothesis Testing Framework</title>
      
      <p>
        In hypothesis testing, we consider two competing hypotheses:
      </p>
      
      <definition xml:id="def-null-hypothesis">
        <title>Null Hypothesis</title>
        <statement>
          <p>
            The <term>null hypothesis</term> (<m>H_0</m>) often represents a skeptical
            perspective or a claim to be tested. It typically represents a position of
            no difference or no effect.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-alternative-hypothesis">
        <title>Alternative Hypothesis</title>
        <statement>
          <p>
            The <term>alternative hypothesis</term> (<m>H_A</m>) represents an alternative
            claim under consideration. It is often represented by a range of possible
            parameter values and is what the researcher hopes to show evidence for.
          </p>
        </statement>
      </definition>
      
      <p>
        Our job as data scientists is to play the role of a skeptic: before we buy into the
        alternative hypothesis, we need to see strong supporting evidence. Even if we fail to
        reject the null hypothesis, we typically do not accept it as true; failing to find
        strong evidence for the alternative hypothesis is not equivalent to accepting the
        null hypothesis.
      </p>
      
      <definition xml:id="def-null-value">
        <title>Null Value</title>
        <statement>
          <p>
            The <term>null value</term> is the value of the parameter under the null
            hypothesis. It is common to label the null value with a subscript 0. For example,
            if the null hypothesis is <m>p = 0.5</m>, then the null value is <m>p_0 = 0.5</m>.
          </p>
        </statement>
      </definition>
      
      <example xml:id="ex-coal-hypotheses">
        <title>Setting up hypotheses for coal energy</title>
        <statement>
          <p>
            Pew Research asked a random sample of 1,000 American adults whether they
            supported the increased usage of coal to produce energy. Set up hypotheses
            to evaluate whether a majority of American adults support or oppose the
            increased usage of coal.
          </p>
        </statement>
        <solution>
          <p>
            The uninteresting result is that there is no majority either way: half support
            and half oppose. The alternative hypothesis would be that there is a majority
            support or oppose (though we don't know which).
          </p>
          <p>
            If <m>p</m> represents the proportion supporting, we write the hypotheses as:
          </p>
          <md>
            <mrow>H_0: \amp\ p = 0.5 \quad \text{(no majority either way)}</mrow>
            <mrow>H_A: \amp\ p \neq 0.5 \quad \text{(there is a majority)}</mrow>
          </md>
          <p>
            In this case, the null value is <m>p_0 = 0.5</m>. This is a <em>two-sided</em>
            test because the alternative hypothesis includes values both less than and
            greater than 0.5.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-ht-confidence-intervals">
      <title>Testing Hypotheses Using Confidence Intervals</title>
      
      <p>
        We can use confidence intervals to evaluate hypothesis tests. If the null value
        falls within the confidence interval, we cannot say the null value is implausible,
        so we cannot reject the null hypothesis. If the null value falls outside the
        confidence interval, it is implausible and we reject the null hypothesis.
      </p>
      
      <example xml:id="ex-coal-ci-test">
        <title>Testing coal hypothesis using confidence interval</title>
        <statement>
          <p>
            In the Pew Research poll, 370 out of 1,000 respondents (37%) supported
            expanding coal energy. Does this provide evidence that a majority opposes
            coal energy expansion? Use a 95% confidence interval.
          </p>
        </statement>
        <solution>
          <p>
            First, construct a 95% confidence interval:
            <md>
              <mrow>SE \amp= \sqrt{\frac{0.37 \times 0.63}{1000}} = 0.0153</mrow>
              <mrow>CI \amp= 0.37 \pm 1.96 \times 0.0153</mrow>
              <mrow>\amp= (0.340, 0.400)</mrow>
            </md>
          </p>
          <p>
            The null value <m>p_0 = 0.5</m> is not in this interval (34.0% to 40.0%).
            Therefore, we reject the null hypothesis. We have strong evidence that a
            majority of American adults oppose expanding coal energy production.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-rosling-infant-vaccination">
        <title>Infant vaccination knowledge using CI</title>
        <statement>
          <p>
            The Rosling Foundation studies public knowledge about global health and
            development. In one study, 50 college-educated adults were asked: "What
            percentage of 1-year-old children in the world today have been vaccinated
            against some disease?" The choices were: (A) 20%, (B) 50%, or (C) 80%.
            Only 12 out of 50 respondents (24%) chose the correct answer (C: 80%).
          </p>
          <p>
            If respondents were simply guessing among the three options, we would
            expect about 33.3% to get it right by chance. Does the data provide
            strong evidence that college-educated adults perform differently than
            random guessing? Test using a 95% confidence interval.
          </p>
        </statement>
        <solution>
          <p>
            First, check conditions. The data come from a simple random sample
            (independence), and <m>n\hat{p} = 50 \times 0.24 = 12 \geq 10</m> and
            <m>n(1-\hat{p}) = 50 \times 0.76 = 38 \geq 10</m> (success-failure).
            Conditions are met.
          </p>
          <p>
            Calculate the standard error:
            <me>SE = \sqrt{\frac{0.24 \times 0.76}{50}} = 0.060</me>
          </p>
          <p>
            Construct the 95% confidence interval:
            <md>
              <mrow>0.24 \pm 1.96 \times 0.060 \amp= 0.24 \pm 0.118</mrow>
              <mrow>\amp= (0.122, 0.358)</mrow>
            </md>
          </p>
          <p>
            The null value is <m>p_0 = 0.333</m> (33.3%), which falls within the
            confidence interval of 12.2% to 35.8%. Therefore, we cannot reject the
            null hypothesis. The data do not provide sufficient evidence that
            college-educated adults perform differently than random guessing on this
            question.
          </p>
          <p>
            <strong>Important note:</strong> Failing to reject <m>H_0</m> does not
            mean we've proven the null hypothesis is true. Perhaps there was an
            actual difference, but we were not able to detect it with the relatively
            small sample of 50 respondents.
          </p>
        </solution>
      </example>
    </subsection>
    
    <subsection xml:id="subsec-decision-errors">
      <title>Decision Errors in Hypothesis Testing</title>
      
      <p>
        Hypothesis tests are not flawless: we can make an incorrect decision based on the data.
      </p>
      
      <definition xml:id="def-type-1-error">
        <title>Type 1 Error</title>
        <statement>
          <p>
            A <term>Type 1 Error</term> is rejecting the null hypothesis when <m>H_0</m>
            is actually true. This is a false positive.
          </p>
        </statement>
      </definition>
      
      <definition xml:id="def-type-2-error">
        <title>Type 2 Error</title>
        <statement>
          <p>
            A <term>Type 2 Error</term> is failing to reject the null hypothesis when the
            alternative hypothesis is actually true. This is a false negative.
          </p>
        </statement>
      </definition>
      
      <table xml:id="table-decision-errors">
        <title>Four possible outcomes in hypothesis testing</title>
        <tabular>
          <row header="yes">
            <cell></cell>
            <cell><m>H_0</m> is true</cell>
            <cell><m>H_A</m> is true</cell>
          </row>
          <row>
            <cell>Reject <m>H_0</m></cell>
            <cell>Type 1 Error</cell>
            <cell>Correct Decision</cell>
          </row>
          <row>
            <cell>Do not reject <m>H_0</m></cell>
            <cell>Correct Decision</cell>
            <cell>Type 2 Error</cell>
          </row>
        </tabular>
      </table>
      
      <p>
        If we reduce how often we make one type of error, we generally make more of the
        other type. The balance is controlled by the significance level.
      </p>
      
      <definition xml:id="def-significance-level">
        <title>Significance Level</title>
        <statement>
          <p>
            The <term>significance level</term> <m>\alpha</m> indicates how often we
            incorrectly reject <m>H_0</m> when it is true. The traditional significance
            level is <m>\alpha = 0.05</m>.
          </p>
        </statement>
      </definition>
    </subsection>
    
    <subsection xml:id="subsec-p-values">
      <title>Formal Testing Using P-values</title>
      
      <definition xml:id="def-p-value">
        <title>P-value</title>
        <statement>
          <p>
            The <term>p-value</term> is the probability of observing data at least as
            favorable to the alternative hypothesis as our current data set, if the null
            hypothesis were true. We typically use a summary statistic of the data, such
            as the sample proportion, to help compute the p-value.
          </p>
        </statement>
      </definition>
      
      <p>
        When evaluating hypotheses for proportions using the p-value method, we use the
        null value <m>p_0</m> (not <m>\hat{p}</m>) when checking the success-failure
        condition and computing the standard error:
      </p>
      
      <me>SE_{\hat{p}} = \sqrt{\frac{p_0(1-p_0)}{n}}</me>
      
      <important>
        <p>
          When using the p-value method to evaluate a hypothesis test, check the
          success-failure condition using the null value <m>p_0</m> instead of using
          the sample proportion. We're supposing the null hypothesis is true, which is
          different from the confidence interval approach.
        </p>
      </important>
      
      <p>
        To compute a p-value:
      </p>
      
      <ol>
        <li>Calculate the Z-score (standardized test statistic):
            <me>Z = \frac{\hat{p} - p_0}{SE_{\hat{p}}}</me></li>
        <li>Find the probability of observing a Z-score at least as extreme as the
            one calculated, using the standard normal distribution.</li>
        <li>For a two-sided test, double the tail probability.</li>
      </ol>
      
      <example xml:id="ex-coal-p-value">
        <title>P-value for coal energy test</title>
        <statement>
          <p>
            Using the coal energy data (<m>\hat{p} = 0.37</m>, <m>n = 1000</m>), compute
            the p-value for testing <m>H_0: p = 0.5</m> versus <m>H_A: p \neq 0.5</m>.
          </p>
        </statement>
        <solution>
          <p>
            First, check conditions using <m>p_0 = 0.5</m>:
            <md>
              <mrow>np_0 \amp= 1000 \times 0.5 = 500 \geq 10 \checkmark</mrow>
              <mrow>n(1-p_0) \amp= 1000 \times 0.5 = 500 \geq 10 \checkmark</mrow>
            </md>
          </p>
          <p>
            Calculate the standard error using <m>p_0</m>:
            <me>SE = \sqrt{\frac{0.5 \times 0.5}{1000}} = 0.0158</me>
          </p>
          <p>
            Compute the Z-score:
            <me>Z = \frac{0.37 - 0.5}{0.0158} = -8.23</me>
          </p>
          <p>
            This is an extremely large Z-score in magnitude. The probability of observing
            a Z-score this extreme (in either tail) is essentially 0. Therefore,
            <m>p\text{-value} &lt; 0.0001</m>.
          </p>
          <p>
            Since the p-value is much less than 0.05, we reject <m>H_0</m>. We have
            extremely strong evidence that a majority of American adults oppose expanding
            coal energy production.
          </p>
        </solution>
      </example>
      
      <example xml:id="ex-nuclear-arms-reduction">
        <title>Nuclear arms reduction support</title>
        <statement>
          <p>
            A Gallup poll conducted in March 2013 found that 56% of a simple random
            sample of 1,028 US adults supported nuclear arms reduction. Does this
            provide convincing evidence that a majority of Americans supported nuclear
            arms reduction at the 5% significance level?
          </p>
        </statement>
        <solution>
          <p>
            Set up hypotheses. We want to test whether a majority (more than 50%)
            support nuclear arms reduction:
            <md>
              <mrow>H_0: \amp\  p = 0.50 \quad \text{(no majority)}</mrow>
              <mrow>H_A: \amp\  p \neq 0.50 \quad \text{(there is a majority)}</mrow>
            </md>
          </p>
          <p>
            <strong>Check conditions:</strong>
          </p>
          <ul>
            <li><strong>Independence:</strong> The poll was a simple random sample,
                so observations are independent.</li>
            <li><strong>Success-failure:</strong> Using the null proportion <m>p_0 = 0.5</m>:
                <m>np_0 = n(1-p_0) = 1028 \times 0.5 = 514 \geq 10</m>. <m>\checkmark</m></li>
          </ul>
          <p>
            <strong>Calculate:</strong> Compute the standard error using <m>p_0 = 0.5</m>:
            <me>SE = \sqrt{\frac{0.5 \times 0.5}{1028}} = 0.0156</me>
          </p>
          <p>
            Calculate the test statistic:
            <me>Z = \frac{0.56 - 0.50}{0.0156} = 3.85</me>
          </p>
          <p>
            For this two-sided test, we need to find the probability in both tails.
            A Z-score of 3.85 is extremely large. Looking at a standard normal table,
            the upper tail area is approximately 0.0001. Doubling this for the two-sided
            test: <m>p\text{-value} = 2 \times 0.0001 = 0.0002</m>.
          </p>
          <p>
            <strong>Conclude:</strong> Since <m>p\text{-value} = 0.0002 &lt; 0.05</m>,
            we reject <m>H_0</m>. The poll provides convincing evidence that a majority
            of Americans supported nuclear arms reduction efforts in March 2013.
          </p>
        </solution>
      </example>
      
      <figure xml:id="fig-nuclear-arms-p-value">
        <caption>The sampling distribution centered at the null value <m>p_0 = 0.5</m> for the nuclear arms test. The tails beyond the observed proportion show the p-value.</caption>
        <image source="images/ch_foundations_for_inf/figures/nuclearArmsReduction/nuclearArmsReductionPValue.pdf" width="70%">
          <description>Normal distribution centered at 0.5 showing tail areas for nuclear arms test</description>
        </image>
      </figure>
      
      <figure xml:id="fig-coal-p-value">
        <caption>The p-value for the coal energy test, shown as the tail areas beyond the observed Z-score.</caption>
        <image source="images/ch_foundations_for_inf/figures/normal_dist_mean_500_se_016/normal_dist_mean_500_se_016.pdf" width="70%">
          <description>Normal distribution showing extremely small tail areas for coal test</description>
        </image>
      </figure>
      
      <assemblage xml:id="ht-procedure">
        <title>Four-step hypothesis test procedure</title>
        <ol>
          <li><strong>Prepare:</strong> Identify the parameter of interest, list
              hypotheses, identify the significance level, and identify <m>\hat{p}</m>
              and <m>n</m>.</li>
          <li><strong>Check:</strong> Verify conditions to ensure <m>\hat{p}</m> is
              nearly normal under <m>H_0</m>. For one-proportion hypothesis tests, use
              the null value to check the success-failure condition.</li>
          <li><strong>Calculate:</strong> If the conditions hold, compute the standard
              error using <m>p_0</m>, compute the Z-score, and identify the p-value.</li>
          <li><strong>Conclude:</strong> Evaluate the hypothesis test by comparing the
              p-value to <m>\alpha</m>, and provide a conclusion in the context of the
              problem.</li>
        </ol>
      </assemblage>
      
      <p>
        Decision rule:
      </p>
      
      <ul>
        <li>If <m>p\text{-value} &lt; \alpha</m>, reject <m>H_0</m> and conclude there
            is strong evidence for <m>H_A</m>.</li>
        <li>If <m>p\text{-value} \geq \alpha</m>, do not reject <m>H_0</m> and conclude
            there is insufficient evidence for <m>H_A</m>.</li>
      </ul>
    </subsection>
    
    <subsection xml:id="subsec-significance-level">
      <title>Choosing a Significance Level</title>
      
      <p>
        Choosing a significance level for a test is important in many contexts. The
        traditional level is <m>\alpha = 0.05</m>, but it can be helpful to adjust the
        significance level based on the application:
      </p>
      
      <ul>
        <li>If making a Type 1 Error is dangerous or especially costly, choose a small
            significance level (e.g., 0.01).</li>
        <li>If a Type 2 Error is relatively more dangerous or costly, choose a higher
            significance level (e.g., 0.10).</li>
      </ul>
      
      <p>
        For medical testing, we might use <m>\alpha = 0.01</m> to reduce false positives.
        For preliminary screening, we might use <m>\alpha = 0.10</m> to catch more
        potential cases.
      </p>
    </subsection>
    
    <subsection xml:id="subsec-one-sided-tests">
      <title>One-Sided Hypothesis Tests</title>
      
      <p>
        Sometimes we are only interested in deviations in one direction. In such cases,
        we use a <term>one-sided test</term>.
      </p>
      
      <p>
        For a one-sided test, the alternative hypothesis takes one of these forms:
      </p>
      
      <ul>
        <li><m>H_A: p &gt; p_0</m> (testing if the parameter is greater than the null value)</li>
        <li><m>H_A: p &lt; p_0</m> (testing if the parameter is less than the null value)</li>
      </ul>
      
      <p>
        For one-sided tests, the p-value is calculated using only the tail area in the
        direction specified by <m>H_A</m>, not both tails.
      </p>
      
      <example xml:id="ex-one-sided-stents">
        <title>One-sided test for stents</title>
        <statement>
          <p>
            A study investigated whether stents might be helpful for patients with
            arterial blockages. Researchers were concerned that stents might actually
            increase the risk of stroke. If 45 out of 224 stent patients experienced
            a stroke within 365 days while only 28 out of 227 control patients did,
            does this provide evidence that stents <em>increase</em> the risk of stroke?
          </p>
        </statement>
        <solution>
          <p>
            Let <m>p_s</m> be the proportion of stroke in the stent group and <m>p_c</m>
            be the proportion in the control group. We're interested in whether
            <m>p_s &gt; p_c</m>. For simplicity, consider the null that they're equal.
          </p>
          <p>
            The hypotheses are:
            <md>
              <mrow>H_0: \amp\ p_s = p_c</mrow>
              <mrow>H_A: \amp\ p_s &gt; p_c</mrow>
            </md>
          </p>
          <p>
            The sample proportions are <m>\hat{p}_s = 45/224 = 0.201</m> and
            <m>\hat{p}_c = 28/227 = 0.123</m>. The difference is
            <m>0.201 - 0.123 = 0.078</m>.
          </p>
          <p>
            After computing the appropriate standard error and test statistic (details
            omitted for space), we find <m>p\text{-value} = 0.028</m>. Since this is
            less than 0.05, we reject the null hypothesis. There is evidence that stents
            increase the risk of stroke within 365 days.
          </p>
        </solution>
      </example>
      
      <warning>
        <p>
          Use one-sided tests only when you have a strong reason to care about
          deviations in only one direction. If you're unsure, use a two-sided test.
        </p>
      </warning>
    </subsection>
    
    <exercises>
      <title>Section 5.3 Exercises</title>
      
      <exercise xml:id="ex-nuclear-arms">
        <statement>
          <p>
            A Gallup poll of 1,028 adults found that 56% favored a nuclear arms reduction
            treaty. Does this provide strong evidence that a majority of American adults
            favor such a treaty? Conduct a hypothesis test using <m>\alpha = 0.05</m>.
          </p>
        </statement>
      </exercise>
      
      <exercise xml:id="ex-type-errors-vaccine">
        <statement>
          <p>
            Consider a hypothesis test for whether a new vaccine is effective at reducing
            infection rates compared to a placebo. Describe what a Type 1 Error and a
            Type 2 Error would mean in this context, and discuss which might be more
            serious.
          </p>
        </statement>
      </exercise>
    </exercises>
  </section>

  <!-- Section 5.4: Chapter 5 review exercises -->
  <section xml:id="sec-ch05-review">
    <title>Chapter 5 Review Exercises</title>
    
    <p>
      This chapter introduced the foundational concepts of statistical inference:
    </p>
    
    <ul>
      <li><strong>Point estimates</strong> provide single best guesses for population
          parameters, but come with sampling error.</li>
      <li><strong>Confidence intervals</strong> provide a range of plausible values for
          parameters, accounting for sampling variability.</li>
      <li><strong>Hypothesis tests</strong> allow us to formally evaluate claims about
          population parameters using sample data.</li>
    </ul>
    
    <p>
      These methods all rely on the Central Limit Theorem, which tells us that sample
      proportions follow an approximately normal distribution when certain conditions
      are met. The same framework extends to other parameters beyond proportions.
    </p>
    
    <exercises>
      <title>Review Exercises</title>
      
      <exercise>
        <statement>
          <p>
            A university wants to estimate the proportion of its students who are
            satisfied with campus dining options. A random sample of 500 students
            finds that 340 are satisfied.
          </p>
          <ol>
            <li>Calculate a 90% confidence interval for the true proportion of
                satisfied students.</li>
            <li>Interpret this interval in context.</li>
            <li>Would a 95% confidence interval be wider or narrower? Why?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise>
        <statement>
          <p>
            A political candidate claims that more than 60% of voters in a district
            support her platform. A poll of 400 randomly selected voters finds that
            252 support her platform.
          </p>
          <ol>
            <li>Set up appropriate hypotheses to test the candidate's claim.</li>
            <li>Calculate the p-value for this test.</li>
            <li>What conclusion would you draw at the <m>\alpha = 0.05</m> level?</li>
          </ol>
        </statement>
      </exercise>
      
      <exercise>
        <statement>
          <p>
            Explain the difference between a confidence interval and a hypothesis test.
            When would you use each method?
          </p>
        </statement>
      </exercise>
      
      <exercise>
        <statement>
          <p>
            A researcher wants to estimate a population proportion with a margin of
            error no larger than 3% at the 95% confidence level. What sample size
            is required? (Hint: Use <m>\hat{p} = 0.5</m> for the most conservative
            estimate.)
          </p>
        </statement>
      </exercise>
    </exercises>
  </section>
</chapter>
